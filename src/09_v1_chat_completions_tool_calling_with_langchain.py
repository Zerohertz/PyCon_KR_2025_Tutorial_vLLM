#!/usr/bin/env .venv/bin/python

import asyncio
import sys
from datetime import datetime
from typing import Any, Dict, List

from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import BaseTool
from langchain_openai import ChatOpenAI
from loguru import logger

read = sys.stdin.readline

BASE_URL = "http://localhost:8000/v1"
MODEL_NAME = "Qwen/Qwen3-0.6B"
STREAM = True  # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ì‚¬ìš©


# LangChain Tool ì •ì˜
class WeatherTool(BaseTool):
    name: str = "get_weather"
    description: str = "íŠ¹ì • ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤"

    def _run(self, city: str) -> str:
        """íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        weather_data = {
            "ì„œìš¸": "ë§‘ìŒ, 22Â°C, ìŠµë„ 45%",
            "ë¶€ì‚°": "íë¦¼, 25Â°C, ìŠµë„ 60%",
            "ëŒ€êµ¬": "ë¹„, 18Â°C, ìŠµë„ 85%",
            "ì¸ì²œ": "ë§‘ìŒ, 20Â°C, ìŠµë„ 50%",
            "ê´‘ì£¼": "íë¦¼, 23Â°C, ìŠµë„ 55%",
            "ëŒ€ì „": "ë§‘ìŒ, 21Â°C, ìŠµë„ 40%",
            "ìš¸ì‚°": "íë¦¼, 24Â°C, ìŠµë„ 65%",
            "ì œì£¼": "ë§‘ìŒ, 26Â°C, ìŠµë„ 70%",
        }
        return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


class CalculatorTool(BaseTool):
    name: str = "calculate"
    description: str = "ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤"

    def _run(self, expression: str) -> str:
        """ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # ë³´ì•ˆìƒ eval ì‚¬ìš©ì€ ê¶Œì¥í•˜ì§€ ì•Šì§€ë§Œ, ì˜ˆì œë¥¼ ìœ„í•´ ì‚¬ìš©
            # ì‹¤ì œë¡œëŠ” ë” ì•ˆì „í•œ ìˆ˜ì‹ íŒŒì„œ ì‚¬ìš© ê¶Œì¥
            allowed_chars = set("0123456789+-*/.() ")
            if not all(c in allowed_chars for c in expression):
                return "ì•ˆì „í•˜ì§€ ì•Šì€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

            result = eval(expression)
            return f"{expression} = {result}"
        except Exception as e:
            return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"


class TimeTool(BaseTool):
    name: str = "get_current_time"
    description: str = "í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤"

    def _run(self) -> str:
        """í˜„ì¬ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        current_time = datetime.now()
        return f"í˜„ì¬ ì‹œê°„: {current_time.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ')}"


class NewsSearchTool(BaseTool):
    name: str = "search_news"
    description: str = "íŠ¹ì • ì£¼ì œì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤"

    def _run(self, topic: str) -> str:
        """íŠ¹ì • ì£¼ì œì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        news_data = {
            "AI": [
                "OpenAI, ìƒˆë¡œìš´ GPT ëª¨ë¸ ë°œí‘œë¡œ AI ì—…ê³„ ì£¼ëª©",
                "í•œêµ­í˜• AI ë°˜ë„ì²´ ê°œë°œ í”„ë¡œì íŠ¸ ë³¸ê²© ì‹œë™",
                "AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ êµ­ì œ í‘œì¤€í™” ë…¼ì˜ í™œë°œ",
            ],
            "íŒŒì´ì¬": [
                "Python 3.13 ì •ì‹ ë¦´ë¦¬ìŠ¤, ì„±ëŠ¥ ëŒ€í­ ê°œì„ ",
                "PyCon Korea 2025, ì—­ëŒ€ ìµœëŒ€ ê·œëª¨ë¡œ ê°œìµœ ì˜ˆì •",
                "Django 5.1 ì—…ë°ì´íŠ¸, ìƒˆë¡œìš´ ê¸°ëŠ¥ ë‹¤ìˆ˜ ì¶”ê°€",
            ],
            "ê¸°ìˆ ": [
                "6G ê¸°ìˆ  í‘œì¤€í™” ì‘ì—… êµ­ì œì ìœ¼ë¡œ ì§„í–‰ ì¤‘",
                "ì–‘ìì»´í“¨í„° ìƒìš©í™”, 2030ë…„ëŒ€ í˜„ì‹¤í™” ì „ë§",
                "ë©”íƒ€ë²„ìŠ¤ í”Œë«í¼, êµìœ¡ ë¶„ì•¼ ì ìš© í™•ì‚°",
            ],
            "ê²½ì œ": [
                "ë°˜ë„ì²´ ì‹œì¥ íšŒë³µì„¸, í•˜ë°˜ê¸° ì„±ì¥ ì „ë§",
                "ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ì‹œì¥, ì„ ë³„ì  íˆ¬ì ê²½í–¥ ê°•í™”",
                "ë””ì§€í„¸ í™”í ê·œì œ ë°©ì•ˆ ì •ë¶€ ì°¨ì›ì—ì„œ ê²€í† ",
            ],
        }

        for keyword, articles in news_data.items():
            if keyword.lower() in topic.lower() or topic.lower() in keyword.lower():
                return f"{keyword} ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤:\n" + "\n".join(
                    [f"â€¢ {article}" for article in articles]
                )

        return f"'{topic}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."


class RestaurantTool(BaseTool):
    name: str = "get_restaurant_recommendations"
    description: str = "íŠ¹ì • ì§€ì—­ì˜ ë§›ì§‘ì„ ì¶”ì²œí•©ë‹ˆë‹¤"

    def _run(self, location: str, cuisine_type: str = "í•œì‹") -> str:
        """íŠ¹ì • ì§€ì—­ì˜ ë§›ì§‘ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
        restaurants = {
            "ì„œìš¸": {
                "í•œì‹": ["ê´‘í™”ë¬¸ í•œì •ì‹", "ëª…ë™ ê°ˆë¹„ì§‘", "ê°•ë‚¨ ì‚¼ê³„íƒ•"],
                "ì¤‘ì‹": ["ì°¨ì´ë‚˜íƒ€ìš´ ì§œì¥ë©´", "í™ì½©ë°˜ì ", "ë¶ê²½ë°˜ì "],
                "ì¼ì‹": ["ìŠ¤ì‹œ ì•¼ë§ˆ", "ë¼ë©˜ íƒ€ë¡œ", "ëˆì¹´ì¸  ë§ˆì¸ "],
            },
            "ë¶€ì‚°": {
                "í•œì‹": ["í•´ìš´ëŒ€ íšŒì„¼í„°", "ê´‘ì•ˆë¦¬ ê°ˆë¹„", "ì„œë©´ ëƒ‰ë©´"],
                "í•´ì‚°ë¬¼": ["ìê°ˆì¹˜ í™œì–´íšŒ", "ë¯¼ë½ìˆ˜ë³€ê³µì› íšŒ", "í•´ë™ìš©ê¶ ë©¸ì¹˜ìŒˆë°¥"],
            },
            "ì œì£¼": {
                "í•œì‹": ["ì œì£¼ í‘ë¼ì§€", "ì˜¬ë ˆêµ­ìˆ˜", "ì„±ì‚° í•´ë¬¼íƒ•"],
                "í•´ì‚°ë¬¼": ["ì„±ì‚°í¬ í™œì „ë³µ", "ìš°ë„ í•´ë¬¼ë¼ë©´", "í‘œì„  ê°ˆì¹˜ì¡°ë¦¼"],
            },
        }

        if location in restaurants:
            if cuisine_type in restaurants[location]:
                recs = restaurants[location][cuisine_type]
                return f"{location} {cuisine_type} ë§›ì§‘ ì¶”ì²œ:\n" + "\n".join(
                    [f"â€¢ {restaurant}" for restaurant in recs]
                )
            else:
                available = list(restaurants[location].keys())
                return f"{location}ì—ì„œëŠ” {', '.join(available)} ìŒì‹ì„ ì¶”ì²œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

        return f"{location}ì˜ ë§›ì§‘ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."


# LangChain Tool ì¸ìŠ¤í„´ìŠ¤ë“¤
LANGCHAIN_TOOLS = [
    WeatherTool(),
    CalculatorTool(),
    TimeTool(),
    NewsSearchTool(),
    RestaurantTool(),
]


async def langchain_streaming_chat(
    client: ChatOpenAI, messages: List[Dict[str, Any]]
) -> str:
    """LangChain Agentë¥¼ ì‚¬ìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… í•¨ìˆ˜"""

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
í•­ìƒ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",
            ),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    # OpenAI Tools Agent ìƒì„±
    agent = create_openai_tools_agent(client, LANGCHAIN_TOOLS, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=LANGCHAIN_TOOLS, verbose=False)

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    user_message = None
    for msg in messages:
        if msg.get("role") == "user":
            user_message = msg.get("content")
            break

    if not user_message:
        return "ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    try:
        logger.info("ğŸ”§ LangChain Agent ì‹¤í–‰ ì‹œì‘")
        result = await agent_executor.ainvoke({"input": user_message})
        logger.info("âœ… LangChain Agent ì‹¤í–‰ ì™„ë£Œ")
        return result.get("output", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ LangChain Agent ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


async def interactive_tool_calling():
    """ëŒ€í™”í˜• Tool Calling ëª¨ë“œ"""

    # vLLM ì„œë²„ì™€ ì—°ê²°ë˜ëŠ” ChatOpenAI ì„¤ì •
    client = ChatOpenAI(
        model=MODEL_NAME,
        base_url=BASE_URL,
        api_key="dummy",  # vLLMì—ì„œëŠ” ì‹¤ì œ API í‚¤ê°€ í•„ìš” ì—†ìŒ
        temperature=0.7,
        max_tokens=1024,
        streaming=True,  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    )

    logger.info("ğŸš€ ëŒ€í™”í˜• LangChain Tool Calling ëª¨ë“œ ì‹œì‘")
    logger.info(f"ğŸ“¡ ì„œë²„: {BASE_URL}")
    logger.info(f"ğŸ¤– ëª¨ë¸: {MODEL_NAME}")
    logger.info(f"ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(LANGCHAIN_TOOLS)}ê°œ")

    logger.info("=" * 60)
    logger.info("ğŸ¤– ëŒ€í™”í˜• LangChain Tool Calling ëª¨ë“œ")
    logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:")
    logger.info("â€¢ ë‚ ì”¨ ì •ë³´ (ì˜ˆ: ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜)")
    logger.info("â€¢ ê³„ì‚°ê¸° (ì˜ˆ: 123 + 456ì„ ê³„ì‚°í•´ì¤˜)")
    logger.info("â€¢ í˜„ì¬ ì‹œê°„ (ì˜ˆ: ì§€ê¸ˆ ëª‡ ì‹œì•¼?)")
    logger.info("â€¢ ë‰´ìŠ¤ ê²€ìƒ‰ (ì˜ˆ: AI ë‰´ìŠ¤ ì°¾ì•„ì¤˜)")
    logger.info("â€¢ ë§›ì§‘ ì¶”ì²œ (ì˜ˆ: ë¶€ì‚° í•´ì‚°ë¬¼ ë§›ì§‘ ì¶”ì²œí•´ì¤˜)")
    logger.info("â€¢ ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥")
    logger.info("=" * 60)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€
    conversation_history = [
        {
            "role": "system",
            "content": """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
í•­ìƒ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",
        }
    ]

    conversation_count = 0

    while True:
        try:
            logger.info("ì‚¬ìš©ì: ")
            user_input = read().strip()

            if user_input.lower() in ["quit", "exit", "ì¢…ë£Œ", "ë‚˜ê°€ê¸°"]:
                logger.info(
                    f"ğŸ‘‹ ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­. ì´ {conversation_count}ë²ˆì˜ ëŒ€í™” ì™„ë£Œ"
                )
                logger.info("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”! ğŸ‘‹")
                break

            if not user_input:
                continue

            conversation_count += 1
            logger.info(f"ğŸ’¬ ëŒ€í™” {conversation_count}: ì‚¬ìš©ì ì…ë ¥ - {user_input}")

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            conversation_history.append({"role": "user", "content": user_input})

            # LangChain Agentë¡œ ì‘ë‹µ ìƒì„±
            logger.info(f"ğŸ¯ ëŒ€í™” {conversation_count}: AI ì‘ë‹µ ìƒì„± ì‹œì‘")
            print("ğŸ¤– ", end="", flush=True)

            result = await langchain_streaming_chat(client, conversation_history.copy())

            # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¥¼ ìœ„í•´ ê¸€ìë³„ë¡œ ì¶œë ¥
            for char in result:
                print(char, end="", flush=True)
                await asyncio.sleep(0.01)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
            print()  # ì¤„ë°”ê¿ˆ

            logger.info(f"âœ… ëŒ€í™” {conversation_count}: AI ì‘ë‹µ ìƒì„± ì™„ë£Œ")

            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append({"role": "assistant", "content": result})

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì¤„ì´ê¸° (ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ìµœê·¼ 10ê°œ ë©”ì‹œì§€)
            if len(conversation_history) > 11:
                removed_count = len(conversation_history) - 11
                conversation_history = [conversation_history[0]] + conversation_history[
                    -10:
                ]
                logger.info(f"ğŸ—‚ï¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì •ë¦¬: {removed_count}ê°œ ë©”ì‹œì§€ ì œê±°")

        except KeyboardInterrupt:
            logger.info("âš ï¸ ì‚¬ìš©ìê°€ Ctrl+Cë¡œ ê°•ì œ ì¢…ë£Œ")
            logger.info("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”! ğŸ‘‹")
            break
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” {conversation_count} ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


async def main():
    logger.info(f"vLLM LangChain Tool Calling ì˜ˆì œ ì‹œì‘ - {MODEL_NAME=}")

    logger.info("ğŸš€ vLLM + LangChain Tool Calling ì˜ˆì œ")
    logger.info(f"ëª¨ë¸: {MODEL_NAME}")
    logger.info(f"ì„œë²„: {BASE_URL}")

    try:
        logger.info("ğŸ¯ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        await interactive_tool_calling()

    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(f"ì˜¤ë¥˜: {str(e)}")
        logger.error("vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:")
        logger.error("$ make serve")


if __name__ == "__main__":
    asyncio.run(main())
