#!/usr/bin/env .venv/bin/python

import asyncio
import json
import sys
from datetime import datetime
from typing import Any, Dict, List

from loguru import logger
from openai import AsyncOpenAI

read = sys.stdin.readline

BASE_URL = "http://localhost:8000/v1"
MODEL_NAME = "Qwen/Qwen3-0.6B"
STREAM = True  # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ì‚¬ìš©


# Tool ì •ì˜ (OpenAI Function Calling í˜•ì‹)
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "íŠ¹ì • ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "ë‚ ì”¨ë¥¼ í™•ì¸í•˜ê³  ì‹¶ì€ ë„ì‹œ ì´ë¦„",
                    }
                },
                "required": ["city"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "ê³„ì‚°í•  ìˆ˜ì‹ (ì˜ˆ: 2+3, 10*5, 100/4)",
                    }
                },
                "required": ["expression"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_time",
            "description": "í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "search_news",
            "description": "íŠ¹ì • ì£¼ì œì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "topic": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‰´ìŠ¤ ì£¼ì œ (ì˜ˆ: AI, íŒŒì´ì¬, ê¸°ìˆ , ê²½ì œ)",
                    }
                },
                "required": ["topic"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_restaurant_recommendations",
            "description": "íŠ¹ì • ì§€ì—­ì˜ ë§›ì§‘ì„ ì¶”ì²œí•©ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "ë§›ì§‘ì„ ì°¾ê³  ì‹¶ì€ ì§€ì—­ (ì˜ˆ: ì„œìš¸, ë¶€ì‚°, ì œì£¼)",
                    },
                    "cuisine_type": {
                        "type": "string",
                        "description": "ìŒì‹ ì¢…ë¥˜ (ì˜ˆ: í•œì‹, ì¤‘ì‹, ì¼ì‹, í•´ì‚°ë¬¼)",
                        "default": "í•œì‹",
                    },
                },
                "required": ["location"],
            },
        },
    },
]


# Tool í•¨ìˆ˜ë“¤ ì •ì˜
def get_weather(city: str) -> str:
    """íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, 22Â°C, ìŠµë„ 45%",
        "ë¶€ì‚°": "íë¦¼, 25Â°C, ìŠµë„ 60%",
        "ëŒ€êµ¬": "ë¹„, 18Â°C, ìŠµë„ 85%",
        "ì¸ì²œ": "ë§‘ìŒ, 20Â°C, ìŠµë„ 50%",
        "ê´‘ì£¼": "íë¦¼, 23Â°C, ìŠµë„ 55%",
        "ëŒ€ì „": "ë§‘ìŒ, 21Â°C, ìŠµë„ 40%",
        "ìš¸ì‚°": "íë¦¼, 24Â°C, ìŠµë„ 65%",
        "ì œì£¼": "ë§‘ìŒ, 26Â°C, ìŠµë„ 70%",
    }
    return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def calculate(expression: str) -> str:
    """ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        # ë³´ì•ˆìƒ eval ì‚¬ìš©ì€ ê¶Œì¥í•˜ì§€ ì•Šì§€ë§Œ, ì˜ˆì œë¥¼ ìœ„í•´ ì‚¬ìš©
        # ì‹¤ì œë¡œëŠ” ë” ì•ˆì „í•œ ìˆ˜ì‹ íŒŒì„œ ì‚¬ìš© ê¶Œì¥
        allowed_chars = set("0123456789+-*/.() ")
        if not all(c in allowed_chars for c in expression):
            return "ì•ˆì „í•˜ì§€ ì•Šì€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

        result = eval(expression)
        return f"{expression} = {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"


def get_current_time() -> str:
    """í˜„ì¬ ì‹œê°„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    current_time = datetime.now()
    return f"í˜„ì¬ ì‹œê°„: {current_time.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ')}"


def search_news(topic: str) -> str:
    """íŠ¹ì • ì£¼ì œì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    news_data = {
        "AI": [
            "OpenAI, ìƒˆë¡œìš´ GPT ëª¨ë¸ ë°œí‘œë¡œ AI ì—…ê³„ ì£¼ëª©",
            "í•œêµ­í˜• AI ë°˜ë„ì²´ ê°œë°œ í”„ë¡œì íŠ¸ ë³¸ê²© ì‹œë™",
            "AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ êµ­ì œ í‘œì¤€í™” ë…¼ì˜ í™œë°œ",
        ],
        "íŒŒì´ì¬": [
            "Python 3.13 ì •ì‹ ë¦´ë¦¬ìŠ¤, ì„±ëŠ¥ ëŒ€í­ ê°œì„ ",
            "PyCon Korea 2025, ì—­ëŒ€ ìµœëŒ€ ê·œëª¨ë¡œ ê°œìµœ ì˜ˆì •",
            "Django 5.1 ì—…ë°ì´íŠ¸, ìƒˆë¡œìš´ ê¸°ëŠ¥ ë‹¤ìˆ˜ ì¶”ê°€",
        ],
        "ê¸°ìˆ ": [
            "6G ê¸°ìˆ  í‘œì¤€í™” ì‘ì—… êµ­ì œì ìœ¼ë¡œ ì§„í–‰ ì¤‘",
            "ì–‘ìì»´í“¨í„° ìƒìš©í™”, 2030ë…„ëŒ€ í˜„ì‹¤í™” ì „ë§",
            "ë©”íƒ€ë²„ìŠ¤ í”Œë«í¼, êµìœ¡ ë¶„ì•¼ ì ìš© í™•ì‚°",
        ],
        "ê²½ì œ": [
            "ë°˜ë„ì²´ ì‹œì¥ íšŒë³µì„¸, í•˜ë°˜ê¸° ì„±ì¥ ì „ë§",
            "ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ì‹œì¥, ì„ ë³„ì  íˆ¬ì ê²½í–¥ ê°•í™”",
            "ë””ì§€í„¸ í™”í ê·œì œ ë°©ì•ˆ ì •ë¶€ ì°¨ì›ì—ì„œ ê²€í† ",
        ],
    }

    for keyword, articles in news_data.items():
        if keyword.lower() in topic.lower() or topic.lower() in keyword.lower():
            return f"{keyword} ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤:\n" + "\n".join(
                [f"â€¢ {article}" for article in articles]
            )

    return f"'{topic}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."


def get_restaurant_recommendations(location: str, cuisine_type: str = "í•œì‹") -> str:
    """íŠ¹ì • ì§€ì—­ì˜ ë§›ì§‘ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    restaurants = {
        "ì„œìš¸": {
            "í•œì‹": ["ê´‘í™”ë¬¸ í•œì •ì‹", "ëª…ë™ ê°ˆë¹„ì§‘", "ê°•ë‚¨ ì‚¼ê³„íƒ•"],
            "ì¤‘ì‹": ["ì°¨ì´ë‚˜íƒ€ìš´ ì§œì¥ë©´", "í™ì½©ë°˜ì ", "ë¶ê²½ë°˜ì "],
            "ì¼ì‹": ["ìŠ¤ì‹œ ì•¼ë§ˆ", "ë¼ë©˜ íƒ€ë¡œ", "ëˆì¹´ì¸  ë§ˆì¸ "],
        },
        "ë¶€ì‚°": {
            "í•œì‹": ["í•´ìš´ëŒ€ íšŒì„¼í„°", "ê´‘ì•ˆë¦¬ ê°ˆë¹„", "ì„œë©´ ëƒ‰ë©´"],
            "í•´ì‚°ë¬¼": ["ìê°ˆì¹˜ í™œì–´íšŒ", "ë¯¼ë½ìˆ˜ë³€ê³µì› íšŒ", "í•´ë™ìš©ê¶ ë©¸ì¹˜ìŒˆë°¥"],
        },
        "ì œì£¼": {
            "í•œì‹": ["ì œì£¼ í‘ë¼ì§€", "ì˜¬ë ˆêµ­ìˆ˜", "ì„±ì‚° í•´ë¬¼íƒ•"],
            "í•´ì‚°ë¬¼": ["ì„±ì‚°í¬ í™œì „ë³µ", "ìš°ë„ í•´ë¬¼ë¼ë©´", "í‘œì„  ê°ˆì¹˜ì¡°ë¦¼"],
        },
    }

    if location in restaurants:
        if cuisine_type in restaurants[location]:
            recs = restaurants[location][cuisine_type]
            return f"{location} {cuisine_type} ë§›ì§‘ ì¶”ì²œ:\n" + "\n".join(
                [f"â€¢ {restaurant}" for restaurant in recs]
            )
        else:
            available = list(restaurants[location].keys())
            return f"{location}ì—ì„œëŠ” {', '.join(available)} ìŒì‹ì„ ì¶”ì²œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

    return f"{location}ì˜ ë§›ì§‘ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."


# Tool í•¨ìˆ˜ ë§¤í•‘
AVAILABLE_FUNCTIONS = {
    "get_weather": get_weather,
    "calculate": calculate,
    "get_current_time": get_current_time,
    "search_news": search_news,
    "get_restaurant_recommendations": get_restaurant_recommendations,
}


async def execute_tool_call(tool_call) -> str:
    """Tool callì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    function_name = tool_call.function.name
    function_args = json.loads(tool_call.function.arguments)

    logger.info(f"ğŸ”§ Tool ì‹¤í–‰ ì‹œì‘: {function_name}")
    logger.info(f"ğŸ“ ì „ë‹¬ëœ ì¸ì: {function_args}")

    if function_name in AVAILABLE_FUNCTIONS:
        function_to_call = AVAILABLE_FUNCTIONS[function_name]
        try:
            if function_name == "get_current_time":
                # get_current_timeì€ ì¸ìê°€ ì—†ìŒ
                result = function_to_call()
            else:
                result = function_to_call(**function_args)

            logger.info(f"âœ… Tool ì‹¤í–‰ ì„±ê³µ: {function_name}")
            logger.info(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼: {result}")
            return result
        except Exception as e:
            error_msg = f"Tool ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logger.error(f"âŒ Tool ì‹¤í–‰ ì‹¤íŒ¨: {function_name} - {error_msg}")
            return error_msg
    else:
        error_msg = f"ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜: {function_name}"
        logger.error(f"âŒ {error_msg}")
        return error_msg


async def stream_response(response):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì²˜ë¦¬í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤."""
    full_content = ""
    chunk_count = 0

    async for chunk in response:
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            print(content, end="", flush=True)
            full_content += content
            chunk_count += 1

    logger.info(f"ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {chunk_count}ê°œ ì²­í¬, {len(full_content)}ì ì‘ë‹µ")
    return full_content


async def chat_with_tools_streaming(
    client: AsyncOpenAI, messages: List[Dict[str, Any]]
) -> str:
    """Tool Callingì„ ì§€ì›í•˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… í•¨ìˆ˜"""

    # ì²« ë²ˆì§¸ ìš”ì²­: Toolì´ í•„ìš”í•œì§€ í™•ì¸ (non-streamingìœ¼ë¡œ tool_calls í™•ì¸)
    response = await client.chat.completions.create(
        model=MODEL_NAME,
        messages=messages,
        tools=TOOLS,
        tool_choice="auto",
        max_tokens=2048,
        temperature=0.7,
        stream=False,  # Tool calls í™•ì¸ì„ ìœ„í•´ non-streaming
    )

    response_message = response.choices[0].message

    # Tool callì´ ì—†ìœ¼ë©´ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¼ë°˜ ì‘ë‹µ ìƒì„±
    if not response_message.tool_calls:
        print("ğŸ¤– ", end="", flush=True)
        streaming_response = await client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=2048,
            temperature=0.7,
            stream=True,
        )
        content = await stream_response(streaming_response)
        print()  # ì¤„ë°”ê¿ˆ
        return content

    # Tool callì´ ìˆìœ¼ë©´ ì‹¤í–‰
    logger.info(
        f"ğŸ”§ Tool Call ê°ì§€: {len(response_message.tool_calls)}ê°œì˜ ë„êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤"
    )
    logger.info(
        f"ğŸ”§ ë„êµ¬ ì‚¬ìš© ì¤‘: {len(response_message.tool_calls)}ê°œì˜ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤..."
    )

    # ì›ë³¸ ë©”ì‹œì§€ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
    messages.append(response_message)

    # ê° tool call ì‹¤í–‰í•˜ê³  ê²°ê³¼ ì €ì¥
    for i, tool_call in enumerate(response_message.tool_calls, 1):
        logger.info(
            f"ğŸš€ Tool {i}/{len(response_message.tool_calls)} ì‹¤í–‰ ì¤‘: {tool_call.function.name}"
        )
        logger.info(f"   {i}. {tool_call.function.name} ì‹¤í–‰ ì¤‘...")
        function_result = await execute_tool_call(tool_call)
        logger.info("âœ… ì™„ë£Œ")
        logger.info(f"ğŸ“¤ Tool {i} ì‹¤í–‰ ì™„ë£Œ: {tool_call.function.name}")

        # Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
        messages.append(
            {
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": tool_call.function.name,
                "content": function_result,
            }
        )

    logger.info("ğŸ¯ ëª¨ë“  Tool ì‹¤í–‰ ì™„ë£Œ, ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...")
    print("ğŸ¤– ", end="", flush=True)

    # Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìƒì„±
    final_response = await client.chat.completions.create(
        model=MODEL_NAME,
        messages=messages,
        max_tokens=2048,
        temperature=0.7,
        stream=True,
    )

    content = await stream_response(final_response)
    print()  # ì¤„ë°”ê¿ˆ
    return content


async def interactive_tool_calling():
    """ëŒ€í™”í˜• Tool Calling ëª¨ë“œ"""

    client = AsyncOpenAI(api_key="dummy", base_url=BASE_URL)
    logger.info("ğŸš€ ëŒ€í™”í˜• Tool Calling ëª¨ë“œ ì‹œì‘")
    logger.info(f"ğŸ“¡ ì„œë²„: {BASE_URL}")
    logger.info(f"ğŸ¤– ëª¨ë¸: {MODEL_NAME}")
    logger.info(f"ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(TOOLS)}ê°œ")

    logger.info("=" * 60)
    logger.info("ğŸ¤– ëŒ€í™”í˜• Tool Calling ëª¨ë“œ")
    logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:")
    logger.info("â€¢ ë‚ ì”¨ ì •ë³´ (ì˜ˆ: ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜)")
    logger.info("â€¢ ê³„ì‚°ê¸° (ì˜ˆ: 123 + 456ì„ ê³„ì‚°í•´ì¤˜)")
    logger.info("â€¢ í˜„ì¬ ì‹œê°„ (ì˜ˆ: ì§€ê¸ˆ ëª‡ ì‹œì•¼?)")
    logger.info("â€¢ ë‰´ìŠ¤ ê²€ìƒ‰ (ì˜ˆ: AI ë‰´ìŠ¤ ì°¾ì•„ì¤˜)")
    logger.info("â€¢ ë§›ì§‘ ì¶”ì²œ (ì˜ˆ: ë¶€ì‚° í•´ì‚°ë¬¼ ë§›ì§‘ ì¶”ì²œí•´ì¤˜)")
    logger.info("â€¢ ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥")
    logger.info("=" * 60)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€
    conversation_history = [
        {
            "role": "system",
            "content": """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
í•­ìƒ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",
        }
    ]

    conversation_count = 0

    while True:
        try:
            logger.info("ì‚¬ìš©ì: ")
            user_input = read().strip()
            if user_input.lower() in ["quit", "exit", "ì¢…ë£Œ", "ë‚˜ê°€ê¸°"]:
                logger.info(
                    f"ğŸ‘‹ ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­. ì´ {conversation_count}ë²ˆì˜ ëŒ€í™” ì™„ë£Œ"
                )
                logger.info("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”! ğŸ‘‹")
                break

            if not user_input:
                continue

            conversation_count += 1
            logger.info(f"ğŸ’¬ ëŒ€í™” {conversation_count}: ì‚¬ìš©ì ì…ë ¥ - {user_input}")

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            conversation_history.append({"role": "user", "content": user_input})

            # Tool callingìœ¼ë¡œ ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
            logger.info(f"ğŸ¯ ëŒ€í™” {conversation_count}: AI ì‘ë‹µ ìƒì„± ì‹œì‘")
            result = await chat_with_tools_streaming(
                client, conversation_history.copy()
            )
            logger.info(f"âœ… ëŒ€í™” {conversation_count}: AI ì‘ë‹µ ìƒì„± ì™„ë£Œ")

            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append({"role": "assistant", "content": result})

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì¤„ì´ê¸° (ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ìµœê·¼ 10ê°œ ë©”ì‹œì§€)
            if len(conversation_history) > 11:
                removed_count = len(conversation_history) - 11
                conversation_history = [conversation_history[0]] + conversation_history[
                    -10:
                ]
                logger.info(f"ğŸ—‚ï¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì •ë¦¬: {removed_count}ê°œ ë©”ì‹œì§€ ì œê±°")

        except KeyboardInterrupt:
            logger.info("âš ï¸ ì‚¬ìš©ìê°€ Ctrl+Cë¡œ ê°•ì œ ì¢…ë£Œ")
            logger.info("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”! ğŸ‘‹")
            break
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” {conversation_count} ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


async def main():
    logger.info(f"vLLM Tool Calling ì˜ˆì œ ì‹œì‘ - {MODEL_NAME=}")

    logger.info("ğŸš€ vLLM + OpenAI API Tool Calling ì˜ˆì œ")
    logger.info(f"ëª¨ë¸: {MODEL_NAME}")
    logger.info(f"ì„œë²„: {BASE_URL}")

    try:
        logger.info("ğŸ¯ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        await interactive_tool_calling()

    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(f"ì˜¤ë¥˜: {str(e)}")
        logger.error("vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:")
        logger.error("$ make serve")


if __name__ == "__main__":
    asyncio.run(main())
