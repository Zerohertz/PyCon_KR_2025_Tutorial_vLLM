[project]
name = "pycon-kr-2025-tutorial-vllm"
version = "0.1.0"
description = "PyCon Korea 2025 Tutorial: vLLM의 OpenAI-Compatible Server 톺아보기"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "guidellm>=0.2.1",
    "huggingface-hub[cli]>=0.33.4",
    "langchain>=0.3.27",
    "langchain-openai>=0.3.29",
    "loguru>=0.7.3",
    "openai>=1.90.0",
    "torch==2.7.0",
    "transformers>=4.53.2",
    "vllm==0.9.2",
]
